# RFC-0011: Runtime, Scheduling & Backpressure

**Status**: Draft
**Authors**: Grism Team
**Last Updated**: 2026-01-21
**Depends on**: RFC-0008, RFC-0010
**Supersedes**: —

---

## 1. Abstract

This RFC defines the **runtime execution environment** for Hypergraph, including:

* Operator scheduling
* Resource management
* Backpressure and flow control
* Cancellation and progress tracking

The runtime is responsible for *making physical plans actually run*—efficiently, fairly, and safely—while preserving all semantic guarantees defined in prior RFCs.

This RFC establishes the **minimum behavioral contract** for any Hypergraph execution runtime.

---

## 2. Scope and Non-Goals

### 2.1 Scope

This RFC specifies:

* Runtime architecture and responsibilities
* Operator scheduling model
* Task lifecycle and state transitions
* Backpressure propagation
* Cancellation and timeout semantics
* Observability hooks

### 2.2 Non-Goals

This RFC does **not** define:

* Cluster resource provisioning
* Autoscaling policies
* Security or authentication
* Query admission control
* Language bindings

---

## 3. Design Principles

1. **Correctness Under Load**
   Backpressure MUST preserve correctness, not just performance.

2. **Explicit Flow Control**
   Implicit buffering is forbidden beyond bounded limits.

3. **Operator-Driven Scheduling**
   Runtime reacts to operator behavior, not vice versa.

4. **Fail Fast, Cleanly**
   Errors propagate deterministically and promptly.

---

## 4. Runtime Architecture

### 4.1 Core Components

A compliant runtime consists of:

* **Execution Engine**
  Drives physical plan execution using Arrow RecordBatch.

* **Scheduler**
  Decides when operators run (Tokio tasks for LocalExecutor, Ray tasks for RayExecutor).

* **Buffer Manager**
  Manages bounded Arrow RecordBatch queues.

* **Backpressure Controller**
  Propagates demand signals across operator boundaries.

* **Metrics & Tracing Layer**
  Provides observability for both local and distributed execution.

---

### 4.2 Execution Graph

At runtime, the physical plan is instantiated as an **execution graph**:

* Nodes = operator instances
* Edges = data channels
* Channels are bounded and directional

The execution graph MUST be acyclic.

---

## 5. Scheduling Model

### 5.1 Task Definition

A **task** is a schedulable unit representing:

* An operator instance
* Or a partition of an operator

Tasks have states:

```
Created → Runnable → Running → Blocked → Completed | Failed | Cancelled
```

---

### 5.2 Scheduling Policy

The scheduler MUST:

* Avoid starvation
* Respect operator dependencies
* Prefer pipeline parallelism
* Respect blocking operator barriers

Scheduling MAY be:

* Cooperative (async)
* Preemptive (threads)
* Distributed (actors)

The policy MUST be configurable.

---

## 6. Operator Readiness & Blocking

Operators signal readiness based on:

* Input availability
* Output buffer capacity
* Internal state (e.g. waiting for all input)

Blocking operators MUST:

* Declare blocking behavior (RFC-0008)
* Explicitly signal phase transitions

---

## 7. Backpressure Model

### 7.1 Backpressure Definition

**Backpressure** is the mechanism by which downstream operators signal upstream operators to slow or stop production.

Backpressure is **mandatory**, not optional.

---

### 7.2 Bounded Buffers

All operator channels MUST be bounded.

Rules:

* Default bounds MUST exist
* Unbounded buffering is forbidden
* Buffer exhaustion triggers backpressure

---

### 7.3 Demand-Driven Flow

The runtime SHOULD implement **pull-based** or **credit-based** flow control:

* Downstream demand governs upstream production
* Upstream operators MUST respect demand signals
* Violations are runtime errors

---

### 7.4 Backpressure Propagation

Backpressure MUST propagate:

* Across operator boundaries
* Across execution modes
* Across distributed nodes (RFC-0010)

Propagation MUST be timely and lossless.

---

## 8. Memory Management Interaction

### 8.1 Memory Accounting

Operators MUST:

* Declare memory usage estimates
* Report actual usage

Runtime MAY:

* Throttle operators
* Trigger early backpressure
* Abort queries exceeding limits

---

### 8.2 Spill & Degradation

Spill-to-disk MAY be supported but MUST:

* Preserve semantics
* Be explicit in operator capabilities
* Surface in EXPLAIN ANALYZE

Silent degradation is forbidden.

---

## 9. Cancellation & Timeouts

### 9.1 Cancellation Semantics

Cancellation MAY be triggered by:

* User request
* Timeout
* Upstream failure

Rules:

* Cancellation MUST propagate immediately
* Operators MUST check cancellation regularly
* Partial results MUST be discarded

---

### 9.2 Timeouts

Timeouts are treated as cancellation with cause.

Runtime MUST:

* Surface timeout cause
* Clean up resources

---

## 10. Error Propagation

Errors encountered by any operator MUST:

* Abort the execution graph
* Cancel all running tasks
* Surface a deterministic error report

Retry is allowed only for:

* Stateless operators
* Explicitly retry-safe stages

---

## 11. Progress Tracking & Observability

### 11.1 Required Metrics

Runtime MUST expose:

* Operator state transitions
* Rows in / out per operator
* Buffer utilization
* Backpressure events
* Execution time per operator

---

### 11.2 Tracing

Execution MUST be traceable end-to-end:

* Logical plan → physical plan → runtime graph
* Correlation IDs preserved
* Distributed spans supported

---

## 12. Fairness & Multi-Query Execution

If multiple queries execute concurrently:

* Runtime MUST enforce fairness
* One query MUST NOT starve others
* Resource caps MUST be respected

Policy is runtime-defined but MUST be documented.

---

## 13. Interaction with Execution Backends

### 13.1 LocalExecutor (Relational)

* High pipeline parallelism with Tokio tasks
* Backpressure mostly CPU/memory driven
* Arrow zero-copy sharing between operators

### 13.2 LocalExecutor (Adjacency)

* Adjacency-driven bursts during Expand operations
* Backpressure critical at Expand boundaries
* Index access patterns may create irregular flow

### 13.3 RayExecutor (Distributed)

* Backpressure propagates across Ray task boundaries
* Network shuffle adds latency to pressure signals
* Plasma store enables zero-copy within nodes

### 13.4 Hybrid Strategy

* Mixed pressure sources from different operator types
* Backend transitions MUST not drop signals
* Runtime must coordinate pressure across different execution models

---

## 14. Relationship to Other RFCs

* **RFC-0008**: Operator interfaces executed by runtime
* **RFC-0010**: Distributed execution relies on runtime semantics
* **RFC-0012**: Storage interaction (future)

RFC-0011 defines **how execution stays alive under stress**.

---

## 15. Open Questions

* Adaptive buffer sizing
* Priority-based scheduling
* Cooperative vs preemptive trade-offs
* Integration with async Rust executors

---

## 16. Conclusion

This RFC defines the **heartbeat of Hypergraph execution**.

> **Operators define work.
> Plans define structure.
> The runtime decides whether the system survives real execution conditions.**
