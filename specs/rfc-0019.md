# RFC-0019: Lance-Based Local Storage Backend

**Status**: Draft
**Authors**: Grism Team
**Created**: 2026-01-23
**Last Updated**: 2026-01-23
**Depends on**: RFC-0009, RFC-0012, RFC-0018, RFC-0102
**Supersedes**: —

---

## 1. Abstract

This RFC defines the **backend-specific implementation** of the Grism storage layer using **Lance datasets on a local filesystem**.

It specifies:

* How Grism storage abstractions (RFC-0012) are mapped onto Lance
* How nodes, hyperedges, and adjacency datasets (RFC-0018) are physically materialized
* How fragments, snapshots, and capabilities are realized in a Lance-backed environment

This RFC is **normative for the local runtime**, but does not constrain other backends such as cloud object storage or distributed filesystems.

---

## 2. Scope and Non-Goals

### 2.1 Scope

This RFC specifies:

* Directory and dataset layout on local filesystem
* Lance dataset schemas for nodes, hyperedges, and adjacency
* Fragment and snapshot realization using Lance
* Storage capability exposure for Lance backend

### 2.2 Non-Goals

This RFC does **not** define:

* Distributed or cloud-backed storage
* Write or mutation semantics
* Compaction or vacuum policies
* Transactional guarantees
* Runtime execution algorithms

---

## 3. Design Principles

### 3.1 Strict Conformance to Storage Abstractions

The Lance backend MUST fully conform to the `Storage` trait defined in RFC-0012.

No execution runtime assumptions are permitted.

---

### 3.2 Lance as a Physical Format, Not a Semantic Layer

Lance is used purely as:

* A columnar persistence format
* A fragment-aware storage engine
* An Arrow-native data source

Lance MUST NOT introduce additional semantics beyond those declared by Grism metadata.

---

### 3.3 Snapshot-First Design

Each Grism `SnapshotId` corresponds to a **stable view** over one or more Lance datasets.

Snapshots are immutable and deterministic.

---

## 4. Filesystem Layout

The Lance local storage backend organizes data under a single root directory:

```
<grism_root>/
├── snapshots/
│   └── <snapshot_id>/
│       ├── nodes/
│       │   └── <label>.lance/
│       ├── hyperedges/
│       │   └── <label>.lance/
│       └── adjacency/
│           └── <adjacency_spec>.lance/
└── metadata/
    └── snapshot_index.json
```

No dataset spans multiple snapshots.

---

## 5. Node Dataset Implementation

### 5.1 Dataset Mapping

Each node label maps to one Lance dataset:

```
Node::<Label> → <snapshot>/nodes/<label>.lance
```

### 5.2 Schema

```
node_id        : UInt64
<property cols>
```

Properties:

* `node_id` is dense within a snapshot
* Property columns map 1:1 to Arrow fields

---

## 6. Hyperedge Dataset Implementation

### 6.1 Dataset Mapping

```
Hyperedge::<Label> → <snapshot>/hyperedges/<label>.lance
```

### 6.2 Schema

```
edge_id        : UInt64
arity          : UInt32
role_descriptor: Struct / List
<property cols>
```

Hyperedges are scanned like entities and contain no adjacency data.

---

## 7. Adjacency Dataset Implementation

### 7.1 Dataset Mapping

Each adjacency specification maps to a dedicated Lance dataset:

```
Adjacency::<EdgeLabel>::<AdjSpec> → <snapshot>/adjacency/<name>.lance
```

Multiple adjacency datasets MAY exist per edge label.

---

### 7.2 Schema

Adjacency datasets use a topology-oriented schema:

```
anchor_id   : UInt64
neighbor_id : UInt64
edge_id     : UInt64
<optional role metadata>
```

Rows are logically grouped by `anchor_id`.

---

### 7.3 Fragmentation

Lance fragments correspond directly to Grism `AdjacencyFragment`s.

* Fragment boundaries are snapshot-stable
* Each fragment exposes `AdjacencyFragmentMeta`

CSR-style offsets MAY be encoded implicitly via sorted `anchor_id` ordering.

---

## 8. Fragment and Snapshot Semantics

### 8.1 Fragment Mapping

| Grism Concept | Lance Concept      |
| ------------- | ------------------ |
| FragmentMeta  | Lance Fragment     |
| SnapshotId    | Snapshot directory |

Fragments are immutable and addressable via metadata.

---

### 8.2 Snapshot Resolution

`Storage::resolve_snapshot()` resolves to a concrete snapshot directory.

No implicit snapshot creation is permitted.

---

## 9. Storage Capabilities

The Lance backend advertises the following capabilities:

```
StorageCaps {
  predicate_pushdown: true,
  projection_pushdown: true,
  fragment_pruning: true,
  object_store: false,
}
```

Adjacency-specific capabilities are exposed via `AdjacencyCaps`.

---

## 10. Scan Semantics

All scans:

* Return Arrow `RecordBatch` streams
* Are pull-based
* Respect snapshot isolation

Predicate pushdown is delegated to Lance where possible.

---

## 11. Planner and Execution Interaction

Planners and executors interact with Lance storage only via:

* `Storage::scan()`
* Fragment and adjacency metadata

Execution does not inspect Lance datasets directly.

---

## 12. Guarantees

This RFC guarantees:

1. Full compliance with RFC-0012 storage contracts
2. Deterministic snapshot behavior
3. Efficient columnar scans via Lance
4. Explicit, planner-visible adjacency layouts

---

## 13. Relationship to Other RFCs

* **RFC-0012**: Storage abstractions
* **RFC-0018**: Persistent storage & adjacency layout
* **RFC-0009**: Adjacency and access paths
* **RFC-0102**: Execution engine architecture

RFC-0019 defines a **concrete realization** of these abstractions.

---

## 14. Summary

The Lance-based local storage backend provides:

* A production-ready persistent storage layer
* Columnar, fragment-aware datasets
* Explicit adjacency materialization
* Strict separation between storage and execution

This backend serves as the reference implementation for Grism local execution.
