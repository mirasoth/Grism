# RFC-0103: Standalone Storage Architecture

**Status**: Draft
**Authors**: Grism Team
**Created**: 2026-01-23
**Last Updated**: 2026-01-23
**Depends on**: RFC-0012, RFC-0019, RFC-0020, RFC-0102
**Supersedes**: —

---

## 1. Abstract

This RFC defines the **standalone storage architecture** for Grism's local execution engine, providing a unified view of memory and Lance file storage.

It specifies:

* The `StorageProvider` abstraction that unifies backend management
* Tiered storage model with memory as hot tier and Lance as cold tier
* Write path lifecycle from in-memory buffer to persistent storage
* Read path with optional memory caching
* Configuration, initialization, and resource management

This RFC bridges the gap between RFC-0019 (Lance backend) and RFC-0020 (in-memory backend), enabling production deployments where data flows seamlessly between memory and disk.

---

## 2. Scope and Non-Goals

### 2.1 Scope

This RFC specifies:

* StorageProvider component architecture
* Unified storage mode selection and composition
* Memory-Lance tiered data flow
* Flush, eviction, and persistence lifecycle
* Configuration model and defaults
* Initialization and recovery procedures
* Resource management integration

### 2.2 Non-Goals

This RFC does **not** redefine:

* Storage trait interface (RFC-0012)
* Lance dataset schemas or file layout (RFC-0019)
* In-memory data structures (RFC-0020)
* Execution engine architecture (RFC-0102)
* Snapshot or fragment semantics (existing RFCs)
* Distributed or cloud storage (RFC-0021)

---

## 3. Design Principles

### 3.1 Single Entry Point

The `StorageProvider` is the **sole entry point** for all storage operations in the local engine.

Execution contexts, planners, and operators interact with storage exclusively through this provider.

### 3.2 Mode Transparency

Consumers of storage MUST NOT differentiate between memory-only, Lance-only, or tiered modes.

All modes implement the same `Storage` trait with identical semantics.

### 3.3 Explicit Persistence

Data persistence is **never implicit**. Writes to memory are ephemeral until explicitly flushed.

Applications control when data becomes durable.

### 3.4 Graceful Resource Exhaustion

Memory limits are enforced gracefully. When memory is exhausted:

* New writes may trigger automatic flush
* Reads continue from persistent storage
* No silent data loss occurs

---

## 4. StorageProvider Architecture

### 4.1 Component Overview

```
┌──────────────────────────────────────────────────────────────────────────┐
│                         StorageProvider                                  │
│                                                                          │
│  ┌─────────────────────────────────────────────────────────────────────┐ │
│  │                        Storage (trait)                              │ │
│  └─────────────────────────────────────────────────────────────────────┘ │
│                                   ▲                                      │
│           ┌───────────────────────┼───────────────────────┐              │
│           │                       │                       │              │
│  ┌────────┴────────┐    ┌────────┴────────┐    ┌────────┴────────┐       │
│  │  MemoryStorage  │    │  LanceStorage   │    │  TieredStorage  │       │
│  │  (RFC-0020)     │    │  (RFC-0019)     │    │  (this RFC)     │       │
│  └─────────────────┘    └─────────────────┘    └────────┬────────┘       │
│                                                         │                │
│                                               ┌─────────┴─────────┐      │
│                                               │                   │      │
│                                        ┌──────┴──────┐    ┌───────┴─────┐│
│                                        │MemoryTier   │    │ LanceTier   ││
│                                        │(hot)        │    │(cold)       ││
│                                        └─────────────┘    └─────────────┘│
│                                                                          │
│  ┌─────────────────────┐  ┌─────────────────────┐  ┌──────────────────┐  │
│  │   FlushManager      │  │   CacheManager      │  │   WriteBuffer    │  │
│  └─────────────────────┘  └─────────────────────┘  └──────────────────┘  │
└──────────────────────────────────────────────────────────────────────────┘
```

### 4.2 StorageProvider Type

```rust
pub struct StorageProvider {
    mode: StorageMode,
    inner: Arc<dyn Storage>,
    config: StorageConfig,
    state: ProviderState,
}

pub enum StorageMode {
    /// Pure in-memory, no persistence
    Memory,
    /// Pure Lance, all data on disk
    Lance { path: PathBuf },
    /// Memory as hot tier, Lance as cold tier
    Tiered { path: PathBuf },
}
```

### 4.3 Provider State

```rust
struct ProviderState {
    /// Current memory usage in bytes
    memory_usage: AtomicUsize,
    /// Active snapshot reference count
    active_snapshots: AtomicUsize,
    /// Provider lifecycle state
    lifecycle: Mutex<LifecycleState>,
}

enum LifecycleState {
    Uninitialized,
    Ready,
    Flushing,
    Closed,
}
```

---

## 5. Storage Modes

### 5.1 Memory Mode

Memory mode provides ephemeral, low-latency storage.

**Characteristics**:

| Property | Value |
|----------|-------|
| Persistence | None |
| Write latency | Microseconds |
| Read latency | Microseconds |
| Memory bound | Yes (configurable limit) |
| Use case | Testing, prototyping, caching |

**Implementation**: Delegates directly to `MemoryStorage` (RFC-0020).

### 5.2 Lance Mode

Lance mode provides persistent, production storage.

**Characteristics**:

| Property | Value |
|----------|-------|
| Persistence | Full (local filesystem) |
| Write latency | Milliseconds |
| Read latency | Sub-millisecond (columnar scans) |
| Memory bound | No (data on disk) |
| Use case | Production, large datasets |

**Implementation**: Delegates directly to `LanceStorage` (RFC-0019).

### 5.3 Tiered Mode

Tiered mode combines memory and Lance for optimal performance.

**Characteristics**:

| Property | Value |
|----------|-------|
| Persistence | Explicit flush |
| Write latency | Microseconds (to memory) |
| Read latency | Variable (memory cache hits vs Lance) |
| Memory bound | Yes (memory tier limit) |
| Use case | Production with write buffering |

**Behavior**:

* Writes go to memory tier first
* Reads check memory tier, fall back to Lance
* Explicit flush persists memory tier to Lance
* Memory tier may be evicted under pressure

---

## 6. TieredStorage Implementation

### 6.1 Structure

```rust
pub struct TieredStorage {
    /// Hot tier: in-memory data
    memory_tier: MemoryTier,
    /// Cold tier: Lance persistence
    lance_tier: LanceTier,
    /// Flush management
    flush_manager: FlushManager,
    /// Read cache management
    cache_manager: CacheManager,
    /// Configuration
    config: TieredConfig,
}
```

### 6.2 Memory Tier

The memory tier holds unflushed writes and cached reads:

```rust
struct MemoryTier {
    /// Pending writes per dataset, keyed by (DatasetId, SnapshotId)
    write_buffers: RwLock<HashMap<(DatasetId, SnapshotId), WriteBuffer>>,
    /// Cached reads from Lance tier
    read_cache: RwLock<LruCache<CacheKey, Arc<RecordBatch>>>,
    /// Current memory usage
    usage: AtomicUsize,
}
```

### 6.3 Lance Tier

The Lance tier wraps the underlying `LanceStorage`:

```rust
struct LanceTier {
    storage: LanceStorage,
    /// Metadata about persisted snapshots
    snapshot_manifest: RwLock<SnapshotManifest>,
}
```

### 6.4 Write Buffer

Write buffers accumulate in-memory mutations:

```rust
struct WriteBuffer {
    dataset: DatasetId,
    snapshot: SnapshotId,
    batches: Vec<RecordBatch>,
    row_count: usize,
    byte_size: usize,
    created_at: Instant,
}
```

---

## 7. Write Path

### 7.1 Write Flow

```
                        ┌──────────────────┐
                        │   Application    │
                        └────────┬─────────┘
                                 │ write(dataset, batch)
                                 ▼
                        ┌──────────────────┐
                        │ StorageProvider  │
                        └────────┬─────────┘
                                 │
              ┌──────────────────┼──────────────────┐
              │ Memory Mode      │ Tiered Mode      │ Lance Mode
              ▼                  ▼                  ▼
     ┌────────────────┐  ┌──────────────┐  ┌──────────────┐
     │ MemoryStorage  │  │ Memory Tier  │  │ LanceStorage │
     │ (ephemeral)    │  │ (buffered)   │  │ (persistent) │
     └────────────────┘  └──────┬───────┘  └──────────────┘
                                │
                                │ flush()
                                ▼
                        ┌──────────────┐
                        │ Lance Tier   │
                        │ (persistent) │
                        └──────────────┘
```

### 7.2 Write Operations

```rust
impl TieredStorage {
    /// Write a batch to the memory tier
    pub fn write(
        &self,
        dataset: DatasetId,
        batch: RecordBatch,
        snapshot: SnapshotId,
    ) -> Result<WriteReceipt> {
        // 1. Check memory pressure
        let batch_size = batch.get_array_memory_size();
        if !self.can_accept_write(batch_size) {
            // Trigger automatic flush if configured
            if self.config.auto_flush {
                self.flush_oldest()?;
            } else {
                return Err(StorageError::MemoryExhausted);
            }
        }

        // 2. Append to write buffer
        let mut buffers = self.memory_tier.write_buffers.write();
        let key = (dataset, snapshot);
        let buffer = buffers.entry(key).or_insert_with(|| {
            WriteBuffer::new(dataset, snapshot)
        });
        buffer.append(batch);

        // 3. Update memory accounting
        self.memory_tier.usage.fetch_add(batch_size, Ordering::Relaxed);

        Ok(WriteReceipt {
            dataset,
            snapshot,
            persisted: false,
            memory_bytes: batch_size,
        })
    }
}
```

### 7.3 Flush Semantics

Flush transfers data from memory tier to Lance tier:

```rust
impl TieredStorage {
    /// Flush all pending writes for a snapshot
    pub fn flush(&self, snapshot: SnapshotId) -> Result<FlushResult> {
        let mut buffers = self.memory_tier.write_buffers.write();
        let mut flushed_bytes = 0;
        let mut flushed_datasets = Vec::new();

        // Collect buffers for this snapshot
        let keys_to_flush: Vec<_> = buffers.keys()
            .filter(|(_, s)| *s == snapshot)
            .cloned()
            .collect();

        for key in keys_to_flush {
            if let Some(buffer) = buffers.remove(&key) {
                let (dataset, _) = key;
                flushed_bytes += buffer.byte_size;
                
                // Write to Lance tier
                self.lance_tier.write_batches(
                    dataset,
                    snapshot,
                    buffer.batches,
                )?;
                
                flushed_datasets.push(dataset);
            }
        }

        // Update memory accounting
        self.memory_tier.usage.fetch_sub(flushed_bytes, Ordering::Relaxed);

        Ok(FlushResult {
            snapshot,
            datasets: flushed_datasets,
            bytes_flushed: flushed_bytes,
        })
    }
}
```

---

## 8. Read Path

### 8.1 Read Flow

```
                        ┌──────────────────┐
                        │   Application    │
                        └────────┬─────────┘
                                 │ scan(dataset, predicate)
                                 ▼
                        ┌──────────────────┐
                        │ StorageProvider  │
                        └────────┬─────────┘
                                 │
                                 ▼
                        ┌──────────────────┐
                        │  TieredStorage   │
                        └────────┬─────────┘
                                 │
         ┌───────────────────────┼───────────────────────┐
         │                       │                       │
         ▼                       ▼                       ▼
┌────────────────┐      ┌────────────────┐      ┌────────────────┐
│  Read Cache    │──?──▶│  Memory Tier   │──?──▶│  Lance Tier    │
│  (LRU)         │  hit │  (unflushed)   │  hit │  (persisted)   │
└────────────────┘      └────────────────┘      └────────────────┘
         │                       │                       │
         └───────────────────────┴───────────────────────┘
                                 │
                                 ▼
                        ┌──────────────────┐
                        │  Merged Stream   │
                        └──────────────────┘
```

### 8.2 Scan Implementation

```rust
impl Storage for TieredStorage {
    fn scan(
        &self,
        dataset: DatasetId,
        projection: &Projection,
        predicate: Option<Predicate>,
        snapshot: SnapshotId,
    ) -> RecordBatchStream {
        // 1. Check read cache
        let cache_key = CacheKey::new(dataset, snapshot, projection, &predicate);
        if let Some(cached) = self.cache_manager.get(&cache_key) {
            return RecordBatchStream::from_cached(cached);
        }

        // 2. Scan memory tier (unflushed writes)
        let memory_stream = self.memory_tier.scan(
            dataset,
            projection,
            predicate.clone(),
            snapshot,
        );

        // 3. Scan Lance tier (persisted data)
        let lance_stream = self.lance_tier.scan(
            dataset,
            projection,
            predicate,
            snapshot,
        );

        // 4. Merge streams (memory data takes precedence for same keys)
        let merged = MergedStream::new(memory_stream, lance_stream);

        // 5. Optionally cache result
        if self.config.cache_reads {
            CachingStream::new(merged, self.cache_manager.clone(), cache_key)
        } else {
            merged.into()
        }
    }
}
```

### 8.3 Fragment Resolution

Fragment metadata must reflect both tiers:

```rust
impl Storage for TieredStorage {
    fn fragments(
        &self,
        dataset: DatasetId,
        snapshot: SnapshotId,
    ) -> Vec<FragmentMeta> {
        let mut fragments = Vec::new();

        // Memory tier fragments
        if let Some(buffer) = self.memory_tier.get_buffer(dataset, snapshot) {
            fragments.push(FragmentMeta {
                id: FragmentId::memory(buffer.id()),
                row_count: buffer.row_count,
                byte_size: buffer.byte_size,
                location: FragmentLocation::Memory,
            });
        }

        // Lance tier fragments
        fragments.extend(
            self.lance_tier.fragments(dataset, snapshot)
                .into_iter()
                .map(|f| FragmentMeta {
                    location: FragmentLocation::Lance,
                    ..f
                })
        );

        fragments
    }
}
```

---

## 9. Cache Management

### 9.1 Read Cache

The read cache accelerates repeated reads:

```rust
struct CacheManager {
    cache: RwLock<LruCache<CacheKey, CacheEntry>>,
    max_size: usize,
    current_size: AtomicUsize,
}

struct CacheEntry {
    batches: Vec<Arc<RecordBatch>>,
    byte_size: usize,
    access_count: AtomicUsize,
    created_at: Instant,
}
```

### 9.2 Eviction Policy

Cache eviction uses a weighted LRU strategy:

| Factor | Weight | Description |
|--------|--------|-------------|
| Recency | 0.4 | Time since last access |
| Frequency | 0.3 | Access count |
| Size | 0.2 | Memory footprint |
| Age | 0.1 | Time since creation |

```rust
impl CacheManager {
    fn evict_to_fit(&self, needed_bytes: usize) -> Result<()> {
        while self.current_size.load(Ordering::Relaxed) + needed_bytes > self.max_size {
            let victim = self.select_eviction_victim()?;
            self.evict(victim)?;
        }
        Ok(())
    }
}
```

---

## 10. Flush Management

### 10.1 FlushManager

The FlushManager coordinates persistence:

```rust
struct FlushManager {
    /// Pending flush queue
    pending: Mutex<VecDeque<FlushRequest>>,
    /// Active flush operation
    active: AtomicBool,
    /// Flush policies
    policies: FlushPolicies,
}

struct FlushPolicies {
    /// Flush when memory tier exceeds this threshold
    memory_threshold: usize,
    /// Flush when buffer age exceeds this duration
    age_threshold: Duration,
    /// Flush when buffer row count exceeds this
    row_threshold: usize,
}
```

### 10.2 Automatic Flush Triggers

| Trigger | Condition | Action |
|---------|-----------|--------|
| Memory pressure | `usage > memory_threshold` | Flush oldest buffers |
| Buffer age | `buffer.age > age_threshold` | Flush aged buffers |
| Buffer size | `buffer.rows > row_threshold` | Flush large buffers |
| Explicit | User calls `flush()` | Flush specified snapshot |
| Shutdown | Provider closes | Flush all pending |

---

## 11. Configuration

### 11.1 StorageConfig

```rust
pub struct StorageConfig {
    /// Storage mode
    pub mode: StorageMode,
    /// Memory tier configuration
    pub memory: MemoryConfig,
    /// Flush configuration
    pub flush: FlushConfig,
    /// Cache configuration
    pub cache: CacheConfig,
}

pub struct MemoryConfig {
    /// Maximum memory for write buffers (bytes)
    pub write_buffer_limit: usize,
    /// Maximum memory for read cache (bytes)
    pub read_cache_limit: usize,
}

pub struct FlushConfig {
    /// Enable automatic flush on memory pressure
    pub auto_flush: bool,
    /// Memory threshold for automatic flush (fraction, 0.0-1.0)
    pub memory_threshold: f64,
    /// Maximum buffer age before flush
    pub max_buffer_age: Duration,
    /// Maximum buffer rows before flush
    pub max_buffer_rows: usize,
}

pub struct CacheConfig {
    /// Enable read caching
    pub enabled: bool,
    /// Cache TTL
    pub ttl: Option<Duration>,
}
```

### 11.2 Default Configuration

```rust
impl Default for StorageConfig {
    fn default() -> Self {
        Self {
            mode: StorageMode::Memory,
            memory: MemoryConfig {
                write_buffer_limit: 256 * 1024 * 1024,  // 256 MB
                read_cache_limit: 128 * 1024 * 1024,    // 128 MB
            },
            flush: FlushConfig {
                auto_flush: true,
                memory_threshold: 0.8,  // Flush at 80% capacity
                max_buffer_age: Duration::from_secs(300),  // 5 minutes
                max_buffer_rows: 1_000_000,
            },
            cache: CacheConfig {
                enabled: true,
                ttl: Some(Duration::from_secs(60)),
            },
        }
    }
}
```

---

## 12. Initialization and Recovery

### 12.1 Provider Initialization

```rust
impl StorageProvider {
    /// Create a new storage provider
    pub fn new(config: StorageConfig) -> Result<Self> {
        let inner: Arc<dyn Storage> = match &config.mode {
            StorageMode::Memory => {
                Arc::new(MemoryStorage::new())
            }
            StorageMode::Lance { path } => {
                Arc::new(LanceStorage::open(path)?)
            }
            StorageMode::Tiered { path } => {
                Arc::new(TieredStorage::new(path, &config)?)
            }
        };

        Ok(Self {
            mode: config.mode.clone(),
            inner,
            config,
            state: ProviderState::new(),
        })
    }

    /// Open existing storage or create new
    pub fn open_or_create(config: StorageConfig) -> Result<Self> {
        match &config.mode {
            StorageMode::Lance { path } | StorageMode::Tiered { path } => {
                if path.exists() {
                    Self::recover(config)
                } else {
                    Self::new(config)
                }
            }
            StorageMode::Memory => Self::new(config),
        }
    }
}
```

### 12.2 Recovery Procedure

```rust
impl StorageProvider {
    /// Recover from existing Lance storage
    fn recover(config: StorageConfig) -> Result<Self> {
        let path = match &config.mode {
            StorageMode::Lance { path } | StorageMode::Tiered { path } => path,
            StorageMode::Memory => return Self::new(config),
        };

        // 1. Open Lance storage
        let lance_storage = LanceStorage::open(path)?;

        // 2. Load snapshot manifest
        let manifest = lance_storage.load_manifest()?;

        // 3. Validate manifest integrity
        manifest.validate()?;

        // 4. Build storage instance
        let inner: Arc<dyn Storage> = match &config.mode {
            StorageMode::Lance { .. } => Arc::new(lance_storage),
            StorageMode::Tiered { .. } => {
                Arc::new(TieredStorage::from_lance(lance_storage, &config)?)
            }
            _ => unreachable!(),
        };

        Ok(Self {
            mode: config.mode.clone(),
            inner,
            config,
            state: ProviderState::ready(),
        })
    }
}
```

### 12.3 Shutdown

```rust
impl StorageProvider {
    /// Graceful shutdown
    pub fn close(&self) -> Result<()> {
        // 1. Mark as closing
        {
            let mut lifecycle = self.state.lifecycle.lock();
            *lifecycle = LifecycleState::Flushing;
        }

        // 2. Flush all pending writes (if tiered mode)
        if let StorageMode::Tiered { .. } = &self.mode {
            self.flush_all()?;
        }

        // 3. Close underlying storage
        self.inner.close()?;

        // 4. Mark as closed
        {
            let mut lifecycle = self.state.lifecycle.lock();
            *lifecycle = LifecycleState::Closed;
        }

        Ok(())
    }
}

impl Drop for StorageProvider {
    fn drop(&mut self) {
        // Best-effort flush on drop
        let _ = self.close();
    }
}
```

---

## 13. Integration with Execution Engine

### 13.1 ExecutionContext Integration

The `StorageProvider` integrates with RFC-0102's execution context:

```rust
impl LocalExecutionContext {
    pub fn new(
        provider: Arc<StorageProvider>,
        snapshot: SnapshotId,
        config: RuntimeConfig,
    ) -> Self {
        Self {
            storage: provider.storage(),
            snapshot_id: snapshot,
            memory_manager: provider.memory_manager(),
            metrics_sink: None,
            cancellation: CancellationHandle::new(),
        }
    }
}
```

### 13.2 Storage Access

```rust
impl StorageProvider {
    /// Get storage trait object for execution
    pub fn storage(&self) -> Arc<dyn Storage> {
        self.inner.clone()
    }

    /// Get memory manager for execution context
    pub fn memory_manager(&self) -> Arc<dyn MemoryManager> {
        Arc::new(ProviderMemoryManager {
            config: self.config.memory.clone(),
            state: self.state.clone(),
        })
    }
}
```

---

## 14. Error Handling

### 14.1 Error Types

```rust
pub enum StorageError {
    /// Memory limit exceeded
    MemoryExhausted,
    /// Flush operation failed
    FlushFailed { cause: Box<dyn Error> },
    /// Recovery failed
    RecoveryFailed { path: PathBuf, cause: Box<dyn Error> },
    /// Provider not ready
    NotReady { state: LifecycleState },
    /// Snapshot not found
    SnapshotNotFound { id: SnapshotId },
    /// Dataset not found
    DatasetNotFound { id: DatasetId },
    /// Lance error
    Lance(lance::Error),
    /// IO error
    Io(std::io::Error),
}
```

### 14.2 Error Recovery

| Error | Recovery Action |
|-------|-----------------|
| `MemoryExhausted` | Flush oldest buffers, retry write |
| `FlushFailed` | Log error, retain in memory, retry later |
| `RecoveryFailed` | Report to user, offer fresh start |
| `SnapshotNotFound` | Return empty result or error to caller |

---

## 15. Capabilities

### 15.1 Provider Capabilities

```rust
impl StorageProvider {
    pub fn capabilities(&self) -> StorageCaps {
        match &self.mode {
            StorageMode::Memory => StorageCaps {
                predicate_pushdown: false,
                projection_pushdown: true,
                fragment_pruning: true,
                object_store: false,
            },
            StorageMode::Lance { .. } => StorageCaps {
                predicate_pushdown: true,
                projection_pushdown: true,
                fragment_pruning: true,
                object_store: false,
            },
            StorageMode::Tiered { .. } => StorageCaps {
                // Tiered storage can push down to Lance tier
                predicate_pushdown: true,
                projection_pushdown: true,
                fragment_pruning: true,
                object_store: false,
            },
        }
    }
}
```

---

## 16. Guarantees

This RFC guarantees:

1. **Unified Interface**: All storage modes expose identical `Storage` trait
2. **Explicit Persistence**: Data persists only when explicitly flushed
3. **Memory Safety**: Memory limits are enforced without data loss
4. **Recovery**: Tiered and Lance modes recover from existing data
5. **Graceful Shutdown**: Pending data is flushed on close

---

## 17. Relationship to Other RFCs

| RFC | Relationship |
|-----|--------------|
| **RFC-0012** | Defines `Storage` trait that all modes implement |
| **RFC-0019** | Defines `LanceStorage` used by Lance and Tiered modes |
| **RFC-0020** | Defines `MemoryStorage` used by Memory and Tiered modes |
| **RFC-0102** | Defines execution context that consumes `StorageProvider` |

This RFC does **not** redefine any contracts from these RFCs; it specifies composition and lifecycle management.

---

## 18. Summary

The standalone storage architecture provides:

* A unified `StorageProvider` abstraction for the local engine
* Three modes: Memory, Lance, and Tiered
* Clear write and read paths with explicit persistence
* Configuration-driven resource management
* Production-ready initialization and recovery

This architecture enables Grism's local engine to handle workloads from testing to production with consistent semantics and predictable resource usage.
