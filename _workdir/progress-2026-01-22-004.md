---
date: 2026-01-22
session: e2e-logical-benchmark-001
objective: Create E2E benchmark for Python API logical plan validation
status: completed
---

## Objective

Create an end-to-end benchmark that validates all 200 Python API queries from `bench/grism_queries_part1.py` can successfully construct logical plans, and output those plans for future comparison.

## Completed

### 1. Added Missing Stub Exports to grism Module

Added Python bindings for symbols used in the benchmark queries that were not yet implemented:

- **String functions**: `substring`, `replace`, `split` (standalone versions)
- **Conditional**: `when` (alias for `if_`)
- **Predicates**: `exists`, `any_`, `all_`
- **Path functions**: `shortest_path`, `all_paths`
- **Pattern class**: `Pattern` for graph pattern matching

### 2. Created E2E Benchmark Script

Created `bench/run_logical_benchmark.py` that:
- Runs all 200 query functions from `grism_queries_part1.py`
- Uses `FrameCapture` wrapper to intercept `.collect()` calls
- Extracts logical plans via `.explain()` without executing queries
- Outputs JSON results and human-readable reports

### 3. Created Output Directory Structure

- `bench/output/` directory for benchmark results
- `logical_plans.json` - All plans and errors in JSON format
- `benchmark_report.txt` - Human-readable summary

### 4. Added Makefile Targets

- `bench-e2e-logical` - Run the benchmark
- `bench-e2e-logical-verbose` - Run with verbose output

## Files Changed

### New Files
- `bench/run_logical_benchmark.py` - Main benchmark script (358 lines)
- `bench/output/` - Directory for benchmark outputs

### Modified Files
- `src/python/expressions.rs` - Added new functions and Pattern class
- `src/python/mod.rs` - Registered new Python bindings
- `grism/__init__.py` - Exported new symbols
- `grism/_grism.pyi` - Added type stubs for new symbols
- `Makefile` - Added benchmark targets

## Tests

Benchmark results:
- **Total**: 200 queries
- **Passed**: 138 (69%)
- **Failed**: 62 (31%)

Failed queries identify API gaps:
- `group_by()` keyword argument syntax not supported
- `union()` method not implemented on NodeFrame
- Path function parameter differences (`direction` kwarg)
- Some aggregate/project execution not implemented

## Notes

1. The benchmark validates **plan construction**, not execution. This tests the Python API, expression lowering, and logical plan generation.

2. The 62 failing queries are expected - they identify gaps between the proposed API in `grism_queries_part1.py` and the current implementation.

3. Common failure patterns:
   - `TypeError: NodeFrame.group_by() got an unexpected keyword argument` - API uses `group_by(name=expr)` but implementation only supports `group_by(expr)`
   - `AttributeError: 'NodeFrame' object has no attribute 'union'` - Union not yet implemented
   - `RuntimeError: Execution error: NotImplemented` - Some operators don't have execution support yet

4. The benchmark output can be used for regression testing by comparing logical plans across versions.

## Next Steps

- Consider implementing `group_by()` keyword argument support to match proposed API
- Implement `union()` method on NodeFrame
- Add `direction` parameter to path functions
- Use benchmark results to prioritize API implementation work
